---
title: "[ML] YOLO series"
excerpt: "You only look once(YOLO): Real-Time Object Detection"

categories:
  - MACHINE LEARNING
tags:
  - [YOLO, CNN, object detection]

permalink: /categories/ml/yolo

date: 2022-04-12
last_modified_at: 2022-04-12
---
J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You Only Look Once: Unified, Real-Time Object Detection,” arXiv:1506.02640 [cs], May 2016, Accessed: Apr. 12, 2022. [Online]. Available: http://arxiv.org/abs/1506.02640

- [Overview](#overview)
- [YOLOv2](#yolov2)
- [YOLOv3](#yolov3)
- [Gaussian YOLOv3](#gaussian-yolov3)
- [YOLOv4](#yolov4)
- [YOLOv5](#yolov5)
- [YOLOvX](#yolovx)

## Overview
YOLO는 realtime object detection 실현을 위해 inference time은 짧으면서도 accuracy는 유지하고자 하는 유명한 모델 중 하나다. accuracy는 자율주행에 활용될 정도로 높지는 않은 듯 보인다. 그래서인지 최초 YOLO에서 제안한 핵심 아이디어인 multi-task를 하나의 regression 문제로 정의한 아이디어는 유지하면서 accuracy를 높히는 방향으로 계속해서 추가적인 버전에 대한 연구가 나오고 있다.

YOLO의 핵심 아이디어는 기존 R-CNN, DPM과 같은 모델에서 주로 bounding box를 predict 하는 것과 해당 object가 무엇인지 미리 정의 된 class중 선택하는 classifier가 분리 된 multi-task 문제를 하나의 neural network에서 predict 할 수 있도록 하는 Unified detection 방법을 처음 제안했다는 것.

![Image1](/assets/images/yolo/yolo-image-1.png){: .align-center}  
*The Architecture in the original YOLO paper*  
448x448 image에 대해 7x7 cell grid로 나누고, 일련의 conv layer(darknet 이라 부르는)를 거쳐 마지막 FC layer를 거치면 7x7x30의 output tensor가 나온다. 논문에서는 SxS=7, C=20, B=2인 경우.
- Output tensor : S x S x (B*5+C)  
where **SxS**: grid, **C**: #classes, **B**: #bounding-box, **5**: x,y,w,h,Confidence  
(Confidence는 bounding box에 object가 존재할 확률)  
총 24개 Conv layer, 2 FC layer로 구성되고, Conv layer의 activation function은 leaky ReLU만 적용.  
논문의 셋업을 활용한다면, 448x448 이미지 당 총 98개의 bounding box를 predict 하게 되고 그 bounding box마다 class probabilities를 predict 한다.

- the number of bounding box = 7x7 grid cells, 2 boxes = 98 boxes

![Image2](/assets/images/yolo/yolo-image-2.png){: . width="500px" .align-center}  

- Limiation
  * 하나의 grid cell 당 하나의 object만 detect 하기 때문에 grid cell에 여러 개의 object가 걸쳐있을 경우 missing 하는 경우가 생김.
  * 다양한 aspect ratio에 대한 고려가 특별히 없어서 학습 때 데이터가 충분하지 않으면 새로운 aspec ratio에 대해 prediction이 부정확 할 수 있음

이후 유쾌한 Joseph Redmon 님은 YOLOv2, v3, v5를 제안, v4, x는 다른 곳에서 한 듯.

## YOLOv2
J. Redmon and A. Farhadi, “YOLO9000: Better, Faster, Stronger,” arXiv:1612.08242 [cs], Dec. 2016, Accessed: Apr. 12, 2022. [Online]. Available: http://arxiv.org/abs/1612.08242  
- Darknet-19을 base
- batch norm 추가
- detection을 위한 FC layer를 Convolution layer로 변경
- Bounding box prediction 시 pre-defined Anchor boxes를 초기값으로 변화량만 predict
- Multi scale(3 scales) image로 upsampling 해서 object 크기에 대응?
- Grid cell을 7x7 -> 13x13으로 변경
- Anchor box를 자동으로 찾는 dimension clustering? _[Q] 학습 전에 dataset 가지고 미리 구한다는 뜻?_  

![Image10](/assets/images/yolo/yolo-image-10.png){: . width="400px" .align-center}  
![Image11](/assets/images/yolo/yolo-image-11.png){: . width="400px" .align-center}  
Anchor의 centroid 좌표 (_[Q] Grid cell 좌표가 아닌 Anchor box의 좌표가 별도로 존재하는지? 좌표 체계가 centroid가 맞는지?_) Cx, Cy를 기준으로 0~1 사이의 sigmoid(tx), sigmoid(ty)를 predict 해서 중심 좌표를 옮기는 방식으로 bounding box predict.
Anchor의 width pw, height ph를 기준으로 $e^{t_w}$, $e^{t_y}$만큼 크기를 scaling 함.

- the number of bounding box = 13x13 grid cells, 5anchor boxes = 845 boxes

_[Q] Anchor box 관련된 내용 추가 학습 필요. YOLOv3 paper에 아래 예시가 나옴. Ancor box의 크기를 dataset으로 미리 찾았다는 건지, 좌표는 어떻게 되는지?(그냥 grid cell 좌표인지?)_  
@COCO dataset, 9 clusters were:
(10 × 13), (16 × 30), (33 × 23) / (30 × 61), (62 × 45), (59 × 119) / (116 × 90), (156 × 198), (373 × 326)

## YOLOv3
J. Redmon and A. Farhadi, “YOLOv3: An Incremental Improvement,” arXiv:1804.02767 [cs], Apr. 2018, Accessed: Apr. 12, 2022. [Online]. Available: http://arxiv.org/abs/1804.02767  
![Image9](/assets/images/yolo/yolo-image-9.png){: . width="500px" .align-center}  
YOLOv2의 개선된 버전이라 변경사항 아닌 것들은 그대로 가져감. 
- Darknet-53을 base, residual shortcut connections 포함
- class 예측 시 softmax 대신 각 class에 대해 logistic regression 방식으로 classification 했음.
- detection 시 3개의 scale에 대해 Feature Pyramid Network(FPN) 방식으로 기존 feature extraction 시 가지고 있던 위치 정보를 upsampling 한 feature map에 다시 더하는 방식으로 구성.

![Image3](/assets/images/yolo/yolo-image-3.png){: .align-center}  

- the number of bounding box = 13x13 grid cells/26x26 grid cells/52x52 grid cells 3anchor boxes = 10647 boxes

## Gaussian YOLOv3
J. Choi, D. Chun, H. Kim, and H.-J. Lee, “Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving,” arXiv:1904.04620 [cs], Aug. 2019, Accessed: Apr. 08, 2022. [Online]. Available: http://arxiv.org/abs/1904.04620  

각 bounding box의 class probability x objectness probability으로 detection criterion으로 사용했을 때 bounding box를 잘못 predict 했을 때에 대한 대비가 안된다. x,y,w,h는 실제 좌표값이므로 어느 정도의 confidence를 갖는지 알 수없다.  
bounding box의 uncertainty를 고려하기 위해 좌표가 아니라 mean, variance로 다시 나타내어 mean이 좌표를, variance가 uncertainty를 의미하도록 모델링했다.  
![Image4](/assets/images/yolo/yolo-image-4.png){: . width="500px" .align-center}  
![Image4_2](/assets/images/yolo/yolo-image-4_2.png){: . width="500px" .align-center}  
![Image5](/assets/images/yolo/yolo-image-5.png){: . width="500px" .align-center}  
이에 따라 loss도 다시 설계했다는데 위에 정의한 mean, variance가 실제 loss function에서 mean, variance를 의미하는 것인지? 수식 의미는 시간 날 때 다시 보자.
![Image6](/assets/images/yolo/yolo-image-6.png){: . width="500px" .align-center}  
![Image7](/assets/images/yolo/yolo-image-7.png){: . width="500px" .align-center}  

결국 detection crioterion에 아래와 같은 uncertainty를 고려해서 선택하게 된다.
![Image8](/assets/images/yolo/yolo-image-8.png){: . width="500px" .align-center}  


## YOLOv4

## YOLOv5

## YOLOvX
